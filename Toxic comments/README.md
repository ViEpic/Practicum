## [Проект 6. Поиск токсичных комментариев](toxic-comments.ipynb)


### Цель проекта

Провести исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.

Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.

Входные данные: набор данных с разметкой о токсичности правок.


### Задачи проекта

1. Изучить данные.
2. Подготовить данные.
3. Лемматизировать данные.
4. Построить и обучить модели.
5. Протестировать лучшую модель.
6. Написать общий вывод.

Построим модель со значением метрики качества *F1* не меньше 0.75.


### Навыки и инструменты

- lightgbm
- nltk.corpus
- nltk.stem 
- numpy
- pandas
- python
- re
- sklearn.feature_extraction.text
- sklearn.linear_model
- sklearn.metrics
- sklearn.model_selection
- sklearn.tree
- sklearn.utils


### Общий вывод

1. Лучшая модель градиентного бустинга `LGBMClassifier` на тестовой выборке имеет значение метрики оценки качества *F1* = 0.775.
2. Значение метрики *F1* на тестовой выборке превышает 0.75, что соответсвует изначальному требованию в условии задачи проекта.
